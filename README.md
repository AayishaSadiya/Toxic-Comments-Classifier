# Toxic Comments Classified
 
The Toxic Comments Classifier project is centered around identifying and categorizing toxic comments in text data. Using natural language processing and machine learning, it not only detects toxic comments but also classifies them into categories like toxic, severe toxic, obscene, threat, insult, and identity hate. This valuable tool can be applied to social media platforms, discussion forums, and online communities for identifying and addressing different levels of harmful online content, promoting a safer online environment.





